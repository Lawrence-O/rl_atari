# DQN configuration for Pong

# Environment
env_name: "ALE/Pong-v5"
frame_skip: 4
frame_stack: 4
episode_life: true
clip_rewards: true

# Agent
gamma: 0.99
learning_rate: 0.0001
batch_size: 32
target_update_freq: 10000
double_dqn: true
buffer_size: 100000
memory: "replay"

# Exploration
epsilon_start: 1.0
epsilon_end: 0.01
epsilon_decay: 8000

# Training
num_episodes: 10000
max_steps_per_episode: 10000
evaluation_freq: 500
num_evaluation_episodes: 10
log_freq: 10
save_freq: 200

# Seeds and devices
seed: 42
device: "cuda"  # Use "cpu" if no GPU available